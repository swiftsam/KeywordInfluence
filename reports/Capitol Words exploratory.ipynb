{
 "metadata": {
  "name": "",
  "signature": "sha256:78db1f0de8e6403b5c9b9b474509187691d33751a16d85d61a71653e151b8350"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import csv\n",
      "import psycopg2 as psql\n",
      "import nltk.tokenize as tok\n",
      "import nltk.corpus as corpus\n",
      "import nltk.stem as stem\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "import scipy.io as io"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn    = psql.connect(\"dbname='keyword-influence'\")\n",
      "cursor  = conn.cursor()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_corpus_counts(congress_range, limit='ALL', \\\n",
      "                        ngram_range = (2,2), min_df = 5):\n",
      "    cursor.execute(\"SELECT id, speaking FROM words WHERE CAST(congress AS integer) \" \\\n",
      "                    + congress_range + \" LIMIT \" + str(limit) + \";\")\n",
      "    sql_result = cursor.fetchall()\n",
      "\n",
      "    counter   = CountVectorizer(stop_words = corpus.stopwords.words('english'), \\\n",
      "                                ngram_range =(2, 2), min_df = min_df)\n",
      "\n",
      "    chunks    = map(lambda x: x[1], sql_result)\n",
      "    #chunk_ids = map(lambda x: x[0], sql_result)\n",
      "    \n",
      "    counts    = counter.fit_transform(chunks)\n",
      "    vocab     = counter.get_feature_names()\n",
      "    vocab     = dict(zip(range(len(vocab)),vocab))\n",
      "\n",
      "    return [counts, vocab]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for congress in range(110,107,-1):\n",
      "    results = get_corpus_counts(congress_range = \"=\" + str(congress), min_df = 8)\n",
      "    counts = results[0]\n",
      "    vocab  = results[1]\n",
      "    \n",
      "    writer = csv.writer(open('../data/vocab/vocab_'+str(congress)+'.csv', 'wb'))\n",
      "    for key, value in vocab.items():\n",
      "        writer.writerow([key, value])\n",
      "    io.mmwrite(target = \"../data/counts/counts_\"+str(congress)+\".mtx\", a = counts)\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_rel_freqs(count_matrix):\n",
      "    total_count = count_matrix.sum()\n",
      "    col_sums = np.asarray(count_matrix.sum(2)).flatten()\n",
      "    word_freqs = 1. * col_sums / total_count\n",
      "    return(word_freqs)\n",
      "\n",
      "def get_top_words(count_matrix, vocab, n=5):\n",
      "    rel_freqs   = get_rel_freqs(count_matrix)\n",
      "    top_indexes = rel_freqs.argsort()[::-1][:n] \n",
      "    for i in top_indexes:\n",
      "        print \"%.4f\" % rel_freqs[i] + \" | \" + str(count_matrix[:,i].sum()) + \" | \" + vocab.get(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 673
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rel_freqs = get_rel_freqs(counts)\n",
      "print rel_freqs[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  7.06717623e-05   1.30470946e-04   8.15443411e-05   1.73961261e-04\n",
        "   4.40339442e-04   1.57652393e-04   9.78532093e-05   3.20741075e-04\n",
        "   1.19598367e-04   7.06717623e-05]\n"
       ]
      }
     ],
     "prompt_number": 674
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_top_words(counts, vocab, 30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0127 | 2334 | mr speaker\n",
        "0.0125 | 2297 | united states\n",
        "0.0104 | 1922 | mr president\n",
        "0.0056 | 1029 | unanimous consent\n",
        "0.0054 | 994 | american people\n",
        "0.0052 | 952 | ask unanimous\n",
        "0.0045 | 831 | judiciary committee\n",
        "0.0044 | 803 | president obama\n",
        "0.0038 | 696 | president ask\n",
        "0.0037 | 674 | health care\n",
        "0.0034 | 620 | last year\n",
        "0.0026 | 483 | federal government\n",
        "0.0025 | 463 | small business\n",
        "0.0025 | 456 | rise today\n",
        "0.0025 | 454 | senate republicans\n",
        "0.0025 | 451 | new york\n",
        "0.0024 | 438 | would like\n",
        "0.0024 | 434 | law enforcement\n",
        "0.0023 | 421 | small businesses\n",
        "0.0022 | 409 | speaker rise\n",
        "0.0022 | 406 | judicial nominees\n",
        "0.0022 | 406 | madam president\n",
        "0.0021 | 385 | years ago\n",
        "0.0021 | 382 | home state\n",
        "0.0021 | 381 | president bush\n",
        "0.0020 | 364 | yield floor\n",
        "0.0019 | 357 | house representatives\n",
        "0.0019 | 354 | district court\n",
        "0.0019 | 354 | men women\n",
        "0.0019 | 352 | mr chairman\n"
       ]
      }
     ],
     "prompt_number": 675
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 642
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stemmer = stem.SnowballStemmer(\"english\", ignore_stopwords=True)\n",
      "\n",
      "def token_stem(chunk):\n",
      "    text   = chunk[1]\n",
      "    tokens = tok.word_tokenize(text)\n",
      "    stems  = map(stemmer.stem, tokens)\n",
      "    return [chunk[0], stems]\n",
      "\n",
      "chunks_stemmed = map(token_stem, sql_result)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 521
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "name": "stdout",
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 642
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}